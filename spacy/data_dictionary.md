# Data Dictionary
This file contains linguistic features, their descriptions, functions that can be used to generate them with spacy, and references.

| Feature                              | Function Description                                                                                                                                                                                                                                                                                                                                                            | Feature Description                                                                                                                                                                                                                                                                                                                                                                | Reference/Dataset                                                                                                                                                                                                                                                                         |
|--------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Parts-of-speech Tagging              | Function: `tag ratio()` in `pos_tagging.py`. This function takes in a natural language processor (spacy pipeline), a filepath, and a per word amount. The function calls `pos_tag_counts()` and outputs a dictionary containing the present parts-of-speech tags and Penn Treebank tags in the text, and on average how many instances there are per 100 words.                 | Tagging parts-of-speech in text                                                                                                                                                                                                                                                                                                                                                    | Feature from "Lexical Pipeline" section in [this paper](https://pmc.ncbi.nlm.nih.gov/articles/PMC9421771/).                                                                                                                                                                               |
| Proportion Of Tense-Inflected Verbs  | Function: `num_tense_inflected_verbs` in `syntactic_complexity.py` takes in a natural language processor, filepath, and per word amount. It outputs the number of tense-inflected verbs present, on average, per word amount (default 100)                                                                                                                                      | Tense inflected verbs are defined as past-verbs, present-verbs, and modal auxiliary                                                                                                                                                                                                                                                                                                | Feature from "Lexical Pipeline" section in [this paper](https://pmc.ncbi.nlm.nih.gov/articles/PMC9421771/).                                                                                                                                                                               |
| Idea Density                         | Function: `calculate_idea_density()` in `semantic_complexity.py`. This function takes in a natural language processor, and a filepath. It outputs each sentence of the text and its idea density                                                                                                                                                                                | Idea Density is calculated as the number of propositions divided by the total number of words in a sentence. Propositions include verbs, adjectives, adverbs, prepositions, and conjunctions.                                                                                                                                                                                      | Feature from "Data and Annotation Conventions" section in [this paper](https://ieeexplore.ieee.org/abstract/document/5710404).                                                                                                                                                            |
| Abstractness                         | Function: `abstractness()` in `semantic_complexity.py`. This function calls `generate_noun_feature()` with specified kwargs. This function finds the abstractness value corresponding to each noun in the text utilizing a pre-existing dataset, and averages these values. The function outputs the average abstractness value across all nouns in the text.                   | Abstractness is feature calculated on nouns. The value in the original dataset is a measure of concreteness, however the function uses the inverse of this value.                                                                                                                                                                                                                  | Feature from "Lexical Measures" section in [this paper](https://pmc.ncbi.nlm.nih.gov/articles/PMC8044033/#S2). Dataset from "Electronic and Supplementary Materials" section in [this paper](https://link.springer.com/article/10.3758/s13428-013-0403-5#Sec10). Column used: 'Conc.M'    |
| Semantic Ambiguity                   | Function: `semantic_ambiguity()`in `semantic_complexity.py`. This function calls `generate_noun_feature()` with specified kwargs. This function finds the semantic ambiguity value corresponding to each noun in the text utilizing a pre-existing dataset, and averages these values. The function outputs the average semantic ambiguity value across all nouns in the text.  | Semantic Ambiguity is a feature calculated on nouns. It is a measure of the degree to which the different contexts associated with a given word vary in their meanings.                                                                                                                                                                                                            | Feature from "Lexical Measures" section in [this paper](https://pmc.ncbi.nlm.nih.gov/articles/PMC8044033/#S2). Dataset from "Electronic and Supplementary Materials" section in [this paper](https://link.springer.com/article/10.3758/s13428-012-0278-x#SecESM1). Column used: 'SemD'    |
| Word Frequency                       | Function: `word_frequency()` in `semantic_complexity.py`. This function calls `generate_noun_feature()` with specified kwargs. This function finds the word frequency value corresponding to each noun in the text utilizing a pre-existing dataset, and averages these values. The function outputs the average word frequency value across all nouns in the text.             | Word Frequency is a feature calculated on nouns.  It is defined as word frequency per million words on a log10 scale.                                                                                                                                                                                                                                                              | Feature from "Lexical Measures" section in [this paper](https://pmc.ncbi.nlm.nih.gov/articles/PMC8044033/#S2). Dataset from "Electronic and Supplementary Materials" section in [this paper](https://link.springer.com/article/10.3758/BRM.41.4.977#SecESM1)(ESM 2) Column used: 'Lg10WF' |
| Word Prevalence                      | Function: `word_prevalence()` in `semantic_complexity.py`. This function calls `generate_noun_feature()` with specified kwargs. This function finds the word prevalence value corresponding to each noun in the text utilizing a pre-existing dataset, and averages these values. The function outputs the average word prevalence value across all nouns in the text.          | Word Prevalence is a feature calculated on nouns.                                                                                                                                                                                                                                                                                                                                  | Dataset from "Supplementary Materials" in [this paper](https://link.springer.com/article/10.3758/s13428-018-1077-9#Sec9).                                                                                                                                                                 |
| Word Familiarity                     | Function: `word_familiarity()` in `semantic_complexity.py`. This function calls `generate_noun_feature()` with specified kwargs. This function finds the word familiarity value corresponding to each noun in the text utilizing a pre-existing dataset, and averages these values. The function outputs the average word familiarity value across all nouns in the text.       | Word Familiarity is a feature calculated on nouns.                                                                                                                                                                                                                                                                                                                                 | Feature from "Lexical Measures" section in [this paper](https://pmc.ncbi.nlm.nih.gov/articles/PMC8044033/#S2). Dataset from "Supplementary Materials" in [this paper](https://link.springer.com/article/10.3758/s13428-018-1077-9#Sec9) Column used: 'Pknown'                             |
| Age of acquisition                   | Function: `age_of_acquisition()` in `semantic_complexity.py`. This function calls `generate_noun_feature()` with specified kwargs. This function finds the age of acquisition value corresponding to each noun in the text utilizing a pre-existing dataset, and averages these values. The function outputs the average age of acquisition value across all nouns in the text. | Age of Acquisition is a feature calculated on nouns. It is a score based on what age humans are when the acquire the word.                                                                                                                                                                                                                                                         | Feature from "Lexical Measures" section in [this paper](https://pmc.ncbi.nlm.nih.gov/articles/PMC8044033/#S2).                                                                                                                                                                            |
| Frequency of Non-Words               | Function: `nonword_frequency()` in `syntactic_errors.py`. This function takes in a natural language processor, filepath, dataset path, and per word amount. It uses the dataset to find all occurrences of nonwords in the text. The function outputs, on average, how many nonwords are present per 100 words.                                                                 | Non words are defined as groupings of letters that do not form a valid English word such as "jjksj". Note: this feature can confuse uncommon proper nouns with non words.                                                                                                                                                                                                          | Feature from "Lexical Measures" section in [this paper](https://pmc.ncbi.nlm.nih.gov/articles/PMC8044033/#S2). Dataset from [kaggle](https://www.kaggle.com/datasets/bwandowando/479k-english-words)                                                                                      |
| Sentence Length                      | Function:`sentence_lengths()` in `syntactic_complexity.py`. This function takes in a natural language processor and a filepath. It calculates the length of each sentence and returns a list of sentence lengths.                                                                                                                                                               | Number of words in a sentence as a measure of complexity.                                                                                                                                                                                                                                                                                                                          | Feature from [this paper](https://journals.sagepub.com/doi/full/10.1177/13872877251319401)                                                                                                                                                                                                |
| Most Common Word and Occurrences     | Function: `most_frequent_word()` in `lexical_repetition.py`. This function takes in a natural language processor and a filepath. It calculates and returns the most commonly occurring word and how many times it appears in the text.                                                                                                                                          | Counts word amounts and returns the most frequently occurring word and how many times it occurs. The feature excludes stop words (is, the, a ect..).                                                                                                                                                                                                                               | Feature from [this paper](https://journals.sagepub.com/doi/full/10.1177/13872877251319401)                                                                                                                                                                                                |
| Moving Average Text Token Ratio      | Function: `windowed_text_token_ratio()` in `lexical_variation.py`. This function takes in a natural language processor, filepath, and window size. It averages type token ratio across moving windows and returns this value.                                                                                                                                                   | Moving Average Type Token Ratio calculates type token ratio in windows of a specified size, starting from the first word and moving one word at a time through the document. The result is the average type token ratio across all windows. This is a more stable measure of lexical diversity than standard type token ratio, as its value is not skewed by the size of the text. | Feature from "Lexical Measures" section in [this paper](https://pmc.ncbi.nlm.nih.gov/articles/PMC8044033/#S2).                                                                                                                                                                            |
| Incorrectly Followed Articles        | Function: `incorrectly_followed_articles()` in `syntactic_errors.py`. This function takes in a natural language processor and filepath. It calculates and returns the number of articles (a, and, the) that are not followed by an adjective, noun, or, proper noun.                                                                                                            | Counts articles (a, an, the) not followed by a noun, proper noun, or adjective. Also adds to count if the last token in the document is an article.                                                                                                                                                                                                                                | Feature from [this paper](https://journals.sagepub.com/doi/full/10.1177/13872877251319401)                                                                                                                                                                                                |
| Repeating-Unique Word Ratio          | Function: `repeating_unique_word_ratio()` in `lexical_repetition.py`.  This function takes in a natural language processor and filepath. It calculates the ratio of repeating to unique words in the text and outputs this value.                                                                                                                                               | Ratio of repeating to unique words.                                                                                                                                                                                                                                                                                                                                                | Feature from [this paper](https://journals.sagepub.com/doi/full/10.1177/13872877251319401)                                                                                                                                                                                                |
| Avg, Max, Min Dependency Tree Height | Function `dependency_tree_height()` in `syntactic_complexity.py` calls `tree_heights()` in `syntactic_complexity.py` and uses this function to return a list of all dependency tree heights in the text.                                                                                                                                                                        | Returns a list of dependency tree heights. The user can average, max, or min this list as needed                                                                                                                                                                                                                                                                                   | Feature from [this paper](https://journals.sagepub.com/doi/full/10.1177/13872877251319401)                                                                                                                                                                                                |
| Ratio of Nouns/Pronouns/Conjunctions | Functions: `ratio_of_nouns()`, `ratio_of_pronouns()`, `ratio_of_conjunctions()` in `pos_tagging.py`. These functions call `ratio_of_pos()` with specified kwargs and return the proportion of the part of speech to total words in the text.                                                                                                                                    | Ratio of nouns, pronouns, or conjunctions to total words in document.                                                                                                                                                                                                                                                                                                              | Feature from [this paper](https://journals.sagepub.com/doi/full/10.1177/13872877251319401)                                                                                                                                                                                                |
